{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"%idle_timeout 2880\n",
				"%glue_version 5.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 5\n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"key='YOUR KEY'\n",
				"url = f'https://open.jejudatahub.net/api/proxy/1aD5taat1attaa51Db1511b51ab9Da19/{key}'"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"import requests\n",
				"import json"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"import requests\n",
				"import pandas as pd\n",
				"from datetime import datetime, timedelta\n",
				"\n",
				"def fetch_jeju_data(start_date_str, end_date_str, key):\n",
				"    \"\"\"\n",
				"    제주 데이터 허브 API에서 기간별 데이터를 가져오는 함수.\n",
				"\n",
				"    Args:\n",
				"        start_date_str: 시작 날짜 문자열 (YYYYMMDD 형식).\n",
				"        end_date_str: 종료 날짜 문자열 (YYYYMMDD 형식).\n",
				"        api_key: API 키.\n",
				"\n",
				"    Returns:\n",
				"        pandas DataFrame: 모든 날짜의 데이터를 담은 DataFrame.\n",
				"        API 호출 실패 시 None 반환.\n",
				"    \"\"\"\n",
				"\n",
				"    base_url = 'https://open.jejudatahub.net/api/proxy/1aD5taat1attaa51Db1511b51ab9Da19/'\n",
				"    all_data = []\n",
				"\n",
				"    try:\n",
				"        start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
				"        end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
				"    except ValueError:\n",
				"        print(\"날짜 형식이 잘못되었습니다. YYYYMMDD 형식으로 입력해주세요.\")\n",
				"        return None\n",
				"\n",
				"    current_date = start_date\n",
				"    while current_date <= end_date:\n",
				"        search_date = current_date.strftime('%Y%m%d')\n",
				"        url = f'{base_url}{key}?searchDate={search_date}'\n",
				"\n",
				"        try:\n",
				"            response = requests.get(url)\n",
				"            response.raise_for_status()  # HTTP 오류 발생 시 예외 발생\n",
				"\n",
				"            data = response.json()\n",
				"            # API 응답 구조에 따라 데이터 추출 방식 조정 필요\n",
				"            # 예: data['response']['body']['items']['item']\n",
				"            if 'data' in data and isinstance(data['data'], list):\n",
				"                items = data['data']\n",
				"                for item in items:\n",
				"                    item['searchDate'] = search_date #날짜 정보\n",
				"                    all_data.append(item)\n",
				"            else:\n",
				"                print(f\"{search_date} 데이터 없음 또는 API 응답 형식이 예상과 다름: {data}\")\n",
				"\n",
				"        except requests.exceptions.RequestException as e:\n",
				"            print(f\"{search_date} API 요청 실패: {e}\")\n",
				"            return None\n",
				"        except (KeyError, TypeError) as e:\n",
				"            print(f\"{search_date} 데이터 처리 중 오류 발생: {e}, 응답 데이터: {data}\")\n",
				"            return None\n",
				"\n",
				"        current_date += timedelta(days=1)\n",
				"\n",
				"    if all_data:\n",
				"        df = pd.DataFrame(all_data)\n",
				"        return df\n",
				"    else:\n",
				"        return None\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"import boto3\n",
				"import pandas as pd\n",
				"from io import StringIO"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# S3 클라이언트 생성\n",
				"def upload_to_s3(df, bucket_name, s3_key, aws_access_key_id, aws_secret_access_key, aws_region):\n",
				"    try:\n",
				"        # S3 클라이언트 생성\n",
				"        s3_client = boto3.client(\n",
				"            's3',\n",
				"            aws_access_key_id='AWS ACCESS KEY ID',\n",
				"            aws_secret_access_key='AWS SECRET ACCESS KEY',\n",
				"            region_name='YOUR REGION'\n",
				"        )\n",
				"\n",
				"        # DataFrame을 CSV로 변환하여 S3에 업로드\n",
				"        csv_buffer = StringIO()\n",
				"        df.to_csv(csv_buffer, encoding='utf-8-sig', index=False)\n",
				"        csv_buffer.seek(0)\n",
				"\n",
				"        # S3에 업로드\n",
				"        s3_client.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
				"        print(f\"S3에 파일 저장 완료: s3://{bucket_name}/{s3_key}\")\n",
				"    \n",
				"    except Exception as e:\n",
				"        print(f\"S3 업로드 실패: {e}\")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"import boto3\n",
				"import pandas as pd\n",
				"from io import StringIO\n",
				"\n",
				"# S3에 CSV 파일 업로드 함수\n",
				"def upload_to_s3(df, bucket_name, s3_key, aws_access_key_id, aws_secret_access_key, aws_region):\n",
				"    try:\n",
				"        # S3 클라이언트 생성\n",
				"        s3_client = boto3.client(\n",
				"            's3',\n",
				"            aws_access_key_id='AWS ACCESS KEY ',\n",
				"            aws_secret_access_key='AWS SECRET ACCESS KEY',\n",
				"            region_name='YOUR REGION'\n",
				"        )\n",
				"\n",
				"        # DataFrame을 CSV 형식으로 변환하고 메모리 버퍼에 저장\n",
				"        csv_buffer = StringIO()\n",
				"        df.to_csv(csv_buffer, encoding='utf-8-sig', index=False)\n",
				"        csv_buffer.seek(0)  # 버퍼의 시작으로 포인터 이동\n",
				"\n",
				"        # S3에 CSV 파일 업로드\n",
				"        s3_client.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
				"        print(f\"S3에 파일 저장 완료: s3://{bucket_name}/{s3_key}\")\n",
				"    \n",
				"    except Exception as e:\n",
				"        print(f\"S3 업로드 실패: {e}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from datetime import datetime\n",
				"start_date = '20240101'\n",
				"end_date = datetime.now().strftime('%Y%m%d') # 현재 날짜까지  설정. 전체 기간으로 변경 가능\n",
				"\n",
				"# 데이터 가져오기\n",
				"df = fetch_jeju_data(start_date, end_date, key)\n",
				"\n",
				"\n",
				"if df is not None:\n",
				"    print(\"데이터 수집 완료:\")\n",
				"    print(df.head())  # 처음 몇 행 출력\n",
				"    \n",
				"    # S3에 업로드할 파일 경로 지정\n",
				"    s3_bucket_name = 'ip-jeju-airflow'  # S3 버킷 이름\n",
				"    s3_key = 'data/raw/jeju-daily-weather/'  # S3에 저장할 파일 경로\n",
				"\n",
				"    # S3에 데이터 업로드\n",
				"    upload_to_s3(df, s3_bucket_name, s3_key, \n",
				"                 aws_access_key_id='AWS ACCESS KEY ID', \n",
				"                 aws_secret_access_key='AWS SECRET ACCESS KEY',\n",
				"                 aws_region='YOUR REGION')\n",
				"else:\n",
				"    print(\"데이터 수집 실패\")"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
